# Use the following to save the trained model
    model.save('siamese_nn.h5')


import math
import os
import cv2

face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

def detect_faces(img, draw_box=True):
	# convert image to grayscale
	grayscale_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

	# detect faces
	faces = face_cascade.detectMultiScale(grayscale_img, scaleFactor=1.1,
		minNeighbors=5,
        minSize=(30, 30),
        flags=cv2.CASCADE_SCALE_IMAGE)

	face_box, face_coords = None, []

	for (x, y, w, h) in faces:
		if draw_box:
			cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 5)
		face_box = img[y:y+h, x:x+w]
		face_coords = [x,y,w,h]
	return img, face_box, face_coords


if __name__ == "__main__":
	files = os.listdir('sample_faces')
	images = [file for file in files if 'jpg' in file]
	for image in images:
		img = cv2.imread('sample_faces/' + image)
		detected_faces, _, _ = detect_faces(img)
		cv2.imwrite('sample_faces/detected_faces/' + image, detected_faces)


STEP2. ACTIVATE THE CAMERA to capture the true image of user

OpenCV has a function called VideoCapture to activate and capture the image from the webcam

   import cv2
   video_capture = cv2.VideoCapture(0)

def write_on_frame(frame, text, text_x, text_y):
    (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, thickness=2)[0]
    box_coords = ((text_x, text_y), (text_x+text_width+20, text_y-text_height-20))
    cv2.rectangle(frame, box_coords[0], box_coords[1], (255, 255, 255), cv2.FILLED)
    cv2.putText(frame, text, (text_x, text_y-10), cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0,0,0), thickness=2)
    return frame

counter = 5
while True:
       _, frame = video_capture.read()
       frame, face_box, face_coords = face_detection.detect_faces(frame)
       text = 'Image will be taken in {}..'.format(math.ceil(5))
       if face_box is not None:
           frame = write_on_frame(frame, text, face_coords[0],face_coords[1]-10)


cv2.imshow('Video', frame)
cv2.waitKey(1)
counter -= 0.1
if counter <= 0:
           cv2.imwrite('true_img.png', face_box)
           break

# Release the capture
video_capture.release()
cv2.destroyAllWindows()
print("Image Captured")


STEP 3. FACE RECOGNITION

name = input("What is your name?")

import os
import sys
import cv2

from keras.models import load_model
from keras.models import Sequential
from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D
from keras import backend as K
from keras.preprocessing.image import load_img, img_to_array


# Is the trained model available?
files = os.listdir()
if 'siamese_nn.h5' not in files:
    print("Error: Pre-trained Neural Network not found!")
    print("Please run siamese_nn.py first")
    sys.exit()

# validate that the user has not captured his image
if 'true_img.png' not in files:
    print("Error: True image not found!")
    print("Please run onbarding.py first")
    sys.exit()

def euclidean_distance(vectors):
    vector1, vector2 = vectors
    sum_square = K.sum(K.square(vector1 - vector2), axis=1, keepdims=True)
    return K.sqrt(K.maximum(sum_square, K.epsilon()))

def contrastive_loss(Y_true, D):
    margin = 1
    return K.mean(Y_true * K.square(D) + (1 - Y_true) * K.maximum((margin-D),0))

# load pre-trained Siamese neural network
model = load_model('siamese_nn.h5', custom_objects={'contrastive_loss': contrastive_loss, 'euclidean_distance': euclidean_distance})

# prepare the true image
true_img = cv2.imread('true_img.png', 0)
true_img = true_img.astype('float32')/255
true_img = cv2.resize(true_img, (92, 112))
true_img = true_img.reshape(1, true_img.shape[0], true_img.shape[1], 1)

# The next code uses the VideoCapture function in OpenCV to capture a video from the user's webcam, and passes each frame from the video to the face_detection instance.
# Use a fixed-length list (implemented by Python's collections.deque class) of 15 to collect the 15 most recent predictions (one prediction per frame).
# Average the scores from the 15 most recent predictions, and authenticate the user if the average similarity scores is over a certain threshold.

import collections

video_capture = cv2.VideoCapture(0)
preds = collections.deque(maxlen=15)

while True:
    # Capture frame-by-frame
    _, frame = video_capture.read()

    # Detect Faces
    frame, face_img, face_coords = face_detection.detect_faces(frame, draw_box=False)

    if face_img is not None:
        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
        face_img = face_img.astype('float32')/255
        face_img = cv2.resize(face_img, (92, 112))
        face_img = face_img.reshape(1, face_img.shape[0], face_img.shape[1], 1)
        preds.append(1-model.predict([true_img, face_img])[0][0])
        x,y,w,h = face_coords
        if len(preds) == 15 and sum(preds)/15 >= 0.3:
            text = "Identity: {}".format(name)
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 5)
        elif len(preds) < 15:
            text = "Identifying ..."
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 165, 255), 5)
        else:
            text = "Identity Unknown!"
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 5)
        frame = write_on_frame(frame, text, face_coords[0], face_coords[1]-10)

    else:
        preds = collections.deque(maxlen=15) # clear existing predictions if no face detected

    # Display the resulting frame
    cv2.imshow('Video', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# When everything is done, release the capture
video_capture.release()
cv2.destroyAllWindows()